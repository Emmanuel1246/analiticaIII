# -*- coding: utf-8 -*-
"""borrador mod 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kezu_7SKYjxZZWcKOkSQ6gf9EfOBSXGM

#**Librerias e importar datos**
"""

#@title conectar con google drive
from google.colab import drive
drive.mount('/content/drive')

#@title instalar sweetviz
!pip install sweetviz

#@title Importar librerias
import pandas as pd
import numpy as np
import sweetviz as sv
import sqlite3 as sql #### para bases de datos sql
from platform import python_version ## versión de python
from sklearn.metrics import accuracy_score, confusion_matrix,f1_score
import multiprocessing
from sklearn.inspection import permutation_importance
from sklearn.preprocessing import LabelEncoder

#importar librerias necesarias para feature selection
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
from numpy import set_printoptions
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression


from sklearn.feature_selection import SelectKBest, f_regression

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.svm import LinearSVC

from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix,f1_score

import joblib

from sklearn.model_selection import GridSearchCV
from sklearn.svm import LinearSVC
from sklearn.model_selection import train_test_split

from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split

python_version() ### verificar version de python

"""# **Importar datos generales**"""

#@title importar datos generales
bdg= pd.read_csv('/content/drive/MyDrive/Analitica III/Avance 1/general_data.csv',sep=';')
bdg.head()

"""**Limpieza bd y análisis exploratorio**

#**Liempieza de datos**

##**Bd info general**
"""

#Verificación de columnas
bdg.columns

#Dimensiones de la BD
bdg.shape

#Tipos de variales en la BD
bdg.dtypes

#Copia de seguridad de BD
bdgcopy=bdg.copy()
bdgcopy

#Convertir columnas a minuscula
bdgcopy.columns= map(str.lower, bdgcopy.columns)
bdgcopy.head()

#convertir tipos de variable a categorica
bdgcopy=bdgcopy.astype({'education': object,"education": object})
bdgcopy=bdgcopy.astype({'employeeid': object,"employeeid": object})
bdgcopy.dtypes

#corroborar columna employeecount y standardhours, como todos tienen el valor 1 en el primer caso y 8 en el segundo pueden eliminarse las columnas
#ya que no aportan información relevante al modelo, también se elimina over18 ya que todos los empleados son mayores de edad
print(bdgcopy['employeecount'].unique())
print(bdgcopy['standardhours'].unique())
print(bdgcopy['over18'].unique())

#eliminar columnas que no se usen
bdgcopy=bdgcopy.drop(['employeecount'], axis=1)
bdgcopy=bdgcopy.drop(['standardhours'], axis=1)
bdgcopy=bdgcopy.drop(['over18'], axis=1)
bdgcopy.columns

#Verificar nulos
bdgcopy.isnull().sum()

#reemplazar los nulos por 0, ya que todos los nulos se dan en numcompaniesworked y
#totalworkingyears entonces se pueden reemplazar los nulos por un 0 sin afectar la estructura 
bdgcopy=bdgcopy.fillna(0)

#volver a verificar nulos
bdgcopy.isnull().sum().sum()

#estadísticos
bdgcopy.describe()

bdgcopy.dtypes

#verificar que no se repiten registros de un mismo empleado
print(bdgcopy['employeeid'].unique())
print(bdgcopy['employeeid'].count())

bdgcopy.corr()

from matplotlib.pyplot import figure
import seaborn as sns
figure(figsize=(9,6), dpi = 80) # cambiar el tamaño de la grafica
sns.heatmap(bdgcopy.corr(), annot = True) # mapa de calor de las correlaciones

#bdgcopy.corr().unstack().sort_values().head(10)

#sns.pairplot(bdgcopy, height = 1.1, aspect=1.3, plot_kws ={'s':3})

reports = sv.analyze(bdgcopy)
reports.show_html(filepath='SWEETVIZ_REPORT.html', open_browser=True)

reports.show_notebook()

"""## **Limpieza bd encuesta de desempeño de los empleados**

"""

basedd = df= pd.read_csv("/content/drive/MyDrive/Analitica III/Avance 1/manager_survey_data.csv",sep = ",")

basedd.head()

#Verificación de columnas
basedd.columns

#Dimensiones de la BD
basedd.shape

#Tipos de variales en la BD
basedd.dtypes

#Convertir columnas a minuscula
basedd.columns= map(str.lower, basedd.columns)
basedd.head()

#Verificar nulos
basedd.isnull().sum()

#Copia de seguridad de BD
baseddcopy=basedd.copy()
baseddcopy

import plotly.express as px
# crear dataset
dic2 = base = basedd.groupby(['jobinvolvement'])[['employeeid']].sum().sort_values('employeeid', ascending = False).reset_index()

# crear gráfica:
fig2 = px.pie(base, values = 'employeeid', names ='jobinvolvement',
             title= '<b>Encuesta desempeño - participación en el trabajo<b>',
             color_discrete_sequence=px.colors.qualitative.G10)

# agregar detalles a la gráfica:
fig2.update_layout(
    xaxis_title = 'Año',
    yaxis_title = 'Precio de venta',
    template = 'simple_white',
    title_x = 0.5)

fig2.show()

import plotly.express as px
# crear dataset
dic3 = base = basedd.groupby(['performancerating'])[['employeeid']].sum().sort_values('employeeid', ascending = False).reset_index()

# crear gráfica:
fig3 = px.pie(base, values = 'employeeid', names ='performancerating',
             title= '<b>Encuesta desempeño - clasificación de rendimiento<b>',
             color_discrete_sequence=px.colors.qualitative.G10)

# agregar detalles a la gráfica:
fig3.update_layout(
    xaxis_title = 'Año',
    yaxis_title = 'Precio de venta',
    template = 'simple_white',
    title_x = 0.5)

fig3.show()

"""## **Limpieza bd información de retiro de los empleados**"""

bdatar= pd.read_csv("/content/drive/MyDrive/Analitica III/Avance 1/retirement_info.csv",sep = ";")
bdatar.head()

from google.colab import drive
drive.mount('/content/drive')

#Verificación de columnas
bdatar.columns

#Dimensiones de la BD
bdatar.shape

#Tipos de variales en la BD
bdatar.dtypes

#Convertir columnas a minuscula
bdatar.columns= map(str.lower, bdatar.columns)
bdatar.head()

#Verificar nulos
bdatar.isnull().sum()

bdatar

# llenar valores con un valor particular, dado que en la columna está la opción "Others", los 70 nulos por el momento se dejan, para tratarlos mas adelante.
bdatar = bdatar.fillna("Fired")

#verificar datos de columna attrition, como tiene un valor "constante" Yes se 
#elimina la columna
print(bdatar['attrition'].unique())

#eliminar columna attrition
bdatar=bdatar.drop(['attrition'], axis=1)
bdatar

#Verificar nulos
bdatar.isnull().sum()

import plotly.express as px
# crear dataset
dic = base = bdatar.groupby(['resignationreason'])[['employeeid']].sum().sort_values('employeeid', ascending = False).reset_index()
#base['resignationreason'] = base['resignationreason'].replace(dic)
# ExterQual: calidad del material del exterior del edificio

# crear gráfica:
fig = px.pie(base, values = 'employeeid', names ='resignationreason',
             title= '<b>Motivo de renuncia<b>',
             color_discrete_sequence=px.colors.qualitative.G10)

# agregar detalles a la gráfica:
fig.update_layout(
    xaxis_title = 'Año',
    yaxis_title = 'Precio de venta',
    template = 'simple_white',
    title_x = 0.5)

fig.show()

"""## **Limpieza Base de desempeño**"""

df1= pd.read_csv("/content/drive/MyDrive/Analitica III/Avance 1/employee_survey_data.csv",sep = ",")
dfd=df1.copy()

dfd

#Se miran los datos nulos de la base
dfd.isnull().sum()

# guardar la información en un diccionario para posteriormente usarla
diccionario = dfd[['EnvironmentSatisfaction','JobSatisfaction','WorkLifeBalance']].mean().round().to_dict()
diccionario

#Tratar los datos nulos
dfd = dfd[['EmployeeID','EnvironmentSatisfaction','JobSatisfaction','WorkLifeBalance']].fillna(diccionario)

based = dfd.groupby(['EnvironmentSatisfaction'])[['EmployeeID']].count().sort_values('EnvironmentSatisfaction').reset_index()

# crear gráfica
fig = px.pie(based,  values='EmployeeID',names= 'EnvironmentSatisfaction',
             title= '<b>Nivel de satisfacción del ambiente de trabajo<b>',
             color_discrete_sequence=px.colors.qualitative.G10)

# agregar detalles a la gráfica
fig.update_layout(
    xaxis_title = 'Nivel',
    yaxis_title = 'Cantidad de empleados',
    template = 'simple_white',
    title_x = 0.5)

fig.show()

basej = dfd.groupby(['JobSatisfaction'])[['EmployeeID']].count().sort_values('JobSatisfaction', ascending = False).reset_index()

# crear gráfica
figj = px.pie(basej, values='EmployeeID', names= 'JobSatisfaction',
             title= '<b>Nivel de satisfacción laboral<b>',
             color_discrete_sequence=px.colors.qualitative.G10)

# agregar detalles a la gráfica
figj.update_layout(
    xaxis_title = 'Nivel',
    yaxis_title = 'Cantidad de empleados',
    template = 'simple_white',
    title_x = 0.5)

figj.show()

basew = dfd.groupby(['WorkLifeBalance'])[['EmployeeID']].count().sort_values('WorkLifeBalance', ascending = False).reset_index()

# crear gráfica
figw = px.pie(basew, values='EmployeeID', names = 'WorkLifeBalance',
             title= '<b>Nivel de conciliación de la vida laboral y personal<b>',
             color_discrete_sequence=px.colors.qualitative.G10)

# agregar detalles a la gráfica
figw.update_layout(
    xaxis_title = 'Nivel',
    yaxis_title = 'Cantidad de empleados',
    template = 'simple_white',
    title_x = 0.5)

figw.show()

"""#**Unir bases de datos**"""

bdgcopy

baseddcopy

baseddcopy=baseddcopy.drop(['employeeid'], axis=1)

dfd

#primero se unen las bases de datos con 4409 datos
merged_data = pd.concat([bdgcopy,baseddcopy,dfd], axis=1)

merged_data

#verificar nulos de nueva tabla
merged_data.isnull().sum().sum()

#verificar columnas de nueva tabla
merged_data.dtypes

#la columna employeeid se repite 2 veces entonces hay que dejar una sola
merged_data=merged_data.drop(['EmployeeID'], axis=1)
merged_data.dtypes

#ahora se debe unir a la tabla final los datos de los empleados que renunciaron
bdatar

#creamos copia de seguridad de la tabla con 3 bd juntas
empleados=merged_data.copy()

empleados

#unimos la copia empleados con la base bdatar
bdmodelo = pd.merge(empleados, bdatar, on="employeeid", how="left")

bdmodelo

#Crear la columna target con 1 si renunció, 0 si no renunció
bdmodelo["renuncio"] = bdmodelo["retirementtype"].apply(lambda x: 1 if str(x) == "Resignation" else 0)

bdmodelo=bdmodelo.drop("retirementtype", axis=1)

bdmodelo.head(60)

#verificar nulos
bdmodelo.isnull().sum().sum()

#Convertir los nulos que se generaron con los que no renunciaron a un NA
bdmodelo=bdmodelo.fillna("NA")
bdmodelo

#verificar nulos
bdmodelo.isnull().sum().sum()

#Convertir columnas a minuscula
bdmodelo.columns= map(str.lower, bdmodelo.columns)
bdmodelo.head()

"""#**Convertir variables categoricas a numericas**"""

#identificar columnas a convertir
bdmodelo.dtypes

#verificar dimension de la bd
bdmodelo.shape

#eliminar trabajadores que hayan sido despedidos (son 70)
bdmodelo = bdmodelo[~bdmodelo.apply(lambda row: row.astype(str).str.contains('Fired', case=False)).any(axis=1)]
bdmodelo.shape

print(bdmodelo['businesstravel'].unique())
print(bdmodelo['department'].unique())
print(bdmodelo['educationfield'].unique())
print(bdmodelo['gender'].unique())
print(bdmodelo['jobrole'].unique())
print(bdmodelo['maritalstatus'].unique())
print(bdmodelo['resignationreason'].unique())

bdmodelo.columns

# Creamos un objeto LabelEncoder
le = LabelEncoder()

# Aplicamos la codificación de etiquetas a la variable 'color'
bdmodelo['e_businesstravel'] = le.fit_transform(bdmodelo['businesstravel'])
bdmodelo['e_department'] = le.fit_transform(bdmodelo['department'])
bdmodelo['e_educationfield'] = le.fit_transform(bdmodelo['educationfield'])
bdmodelo['e_genderl'] = le.fit_transform(bdmodelo['gender'])
bdmodelo['e_jobrole'] = le.fit_transform(bdmodelo['jobrole'])
bdmodelo['e_maritalstatus'] = le.fit_transform(bdmodelo['maritalstatus'])
bdmodelo['e_resignationreason'] = le.fit_transform(bdmodelo['resignationreason'])
#bdmodelo['e_retirementdate'] = le.fit_transform(bdmodelo['retirementdate'])

# Mostramos las primeras filas de la base de datos para verificar que se haya realizado correctamente la codificación
bdmodelo.head()

#eliminar variables categoricas de la bd
e_bdmodelo=bdmodelo.drop(['businesstravel'], axis=1)
e_bdmodelo=e_bdmodelo.drop(['department'], axis=1)
e_bdmodelo=e_bdmodelo.drop(['educationfield'], axis=1)
e_bdmodelo=e_bdmodelo.drop(['gender'], axis=1)
e_bdmodelo=e_bdmodelo.drop(['jobrole'], axis=1)
e_bdmodelo=e_bdmodelo.drop(['maritalstatus'], axis=1)

e_bdmodelo=e_bdmodelo.drop(['resignationreason'], axis=1)
e_bdmodelo=e_bdmodelo.drop(['e_resignationreason'], axis=1)
e_bdmodelo=e_bdmodelo.drop(['retirementdate'], axis=1)
e_bdmodelo.dtypes

#pasar variable target al final (renuncio)
# Extraemos la columna que queremos mover a la última posición
renuncio = e_bdmodelo.pop('renuncio')

# Agregamos la columna al final del DataFrame
e_bdmodelo['renuncio'] = renuncio

# Mostramos el DataFrame resultante
e_bdmodelo

e_bdmodelo.dtypes

